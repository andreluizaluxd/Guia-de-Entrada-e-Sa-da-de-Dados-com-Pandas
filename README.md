# üìä Guia de Entrada e Sa√≠da de Dados com Pandas

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-green?logo=pandas)
![Status](https://img.shields.io/badge/Status-Ativo-success)

Este reposit√≥rio traz um **guia r√°pido e pr√°tico** dos principais **formatos de entrada e sa√≠da de dados** suportados pela biblioteca [Pandas](https://pandas.pydata.org/).  

> üéØ Ideal para estudantes, analistas de dados e cientistas que precisam de uma **refer√™ncia r√°pida** para salvar e carregar datasets no dia a dia.

---

## üìå Vis√£o Geral

- **Leitura**: `read_*` ‚Üí carrega dados em um `DataFrame` ou `Series`.
- **Escrita**: `to_*` ‚Üí exporta um `DataFrame` ou `Series` para o formato desejado.
- **Tipos**: os formatos podem ser **texto**, **bin√°rio** ou **SQL/Big Data**.

---

## üìë Tabela de Formatos Suportados

| Tipo     | Formato         | Leitura           | Escrita            | Observa√ß√µes                          |
|----------|-----------------|-------------------|--------------------|--------------------------------------|
| Texto    | CSV             | `read_csv`        | `to_csv`           | Mais usado, simples e universal       |
| Texto    | Fixed-width     | `read_fwf`        | -                  | Colunas com largura fixa              |
| Texto    | JSON            | `read_json`       | `to_json`          | Muito usado em APIs                   |
| Texto    | HTML            | `read_html`       | `to_html`          | Extrai tabelas de p√°ginas web         |
| Texto    | LaTeX           | -                 | `styler.to_latex`  | Formatos acad√™micos                   |
| Texto    | XML             | `read_xml`        | `to_xml`           | Dados estruturados em tags            |
| Texto    | Clipboard       | `read_clipboard`  | `to_clipboard`     | Copia/cola da √°rea de transfer√™ncia   |
| Bin√°rio  | Excel           | `read_excel`      | `to_excel`         | Planilhas do Excel                    |
| Bin√°rio  | OpenDocument    | `read_excel`      | -                  | Formato ODS                           |
| Bin√°rio  | HDF5            | `read_hdf`        | `to_hdf`           | Formato bin√°rio eficiente             |
| Bin√°rio  | Feather         | `read_feather`    | `to_feather`       | R√°pido, otimizado para pandas         |
| Bin√°rio  | Parquet         | `read_parquet`    | `to_parquet`       | Big Data, colunar                     |
| Bin√°rio  | ORC             | `read_orc`        | -                  | Formato Hadoop                        |
| Bin√°rio  | MsgPack         | `read_msgpack`    | `to_msgpack`       | ‚ö†Ô∏è Obsoleto                           |
| Bin√°rio  | Stata           | `read_stata`      | `to_stata`         | Pacote estat√≠stico                    |
| Bin√°rio  | SAS             | `read_sas`        | -                  | Pacote estat√≠stico                    |
| Bin√°rio  | SPSS            | `read_spss`       | -                  | Pacote estat√≠stico                    |
| Bin√°rio  | Pickle          | `read_pickle`     | `to_pickle`        | Formato bin√°rio do Python             |
| SQL      | SQL Databases   | `read_sql`        | `to_sql`           | MySQL, PostgreSQL, SQLite...          |
| SQL      | Google BigQuery | `read_gbq`        | `to_gbq`           | Big Data no Google Cloud              |

---

## üíª Exemplos de Uso

### CSV
```python
import pandas as pd

# Leitura
df = pd.read_csv("dados.csv")

# Escrita
df.to_csv("dados_saida.csv", index=False)

---------------------------------------------------------

# Leitura
df = pd.read_json("dados.json")

# Escrita
df.to_json("dados_saida.json", orient="records", lines=True)

---------------------------------------------------------

from sqlalchemy import create_engine
import pandas as pd

# Conex√£o com SQLite (exemplo)
engine = create_engine("sqlite:///meu_banco.db")

# Leitura
df = pd.read_sql("SELECT * FROM tabela_exemplo", con=engine)

# Escrita
df.to_sql("nova_tabela", con=engine, index=False, if_exists="replace")

---------------------------------------------------------



